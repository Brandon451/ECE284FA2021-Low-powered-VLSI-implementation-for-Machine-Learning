1. Please download "[HW1_Prob2]_2-D_Perceptron_Training_with_Gradient_Descent.ipynb" and train the perceptron in the jupyter notebook (7 pt).

    - Study the 3rd cell of "[W1S2_example2]_Perceptron_Training_with_Gradient_Descent.ipynb" and apply the similar approach.

 

2. Please run "[W2S1_example1]_Multi-layer_Perceptron_Back_Propagation.ipynb" (8 pt).

    - calculate the gradients of W1 and W2 manually and submit the hand-written (or typed) solution.

    - check your manual solution by comparing with the results from jupyter notebook.

 

3. Please iterate prob. 2 for "[HW2_prob2b]_DNN_Back_Propagation_with_Negative_Values_at_ReLU.ipynb" (8 pt).

 

4. Please modify the jupyter notebook "[W2S1_example2]_Perceptron_batch_vs_SGD.ipynb" to apply stochastic gradient descent (SGD) based update (7 pt).   